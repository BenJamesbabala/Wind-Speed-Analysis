{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    code_show=false;\n",
       "    function code_toggle() {\n",
       "     if (code_show){\n",
       "     $('div.input').hide();\n",
       "     } else {\n",
       "     $('div.input').show();\n",
       "     }\n",
       "     code_show = !code_show\n",
       "    }\n",
       "    $( document ).ready(code_toggle);\n",
       "    </script>\n",
       "    <form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <script type='text/javascript' src='./lib/my_toc/new.js'></script>\n",
       "        <link rel=\"stylesheet\" type=\"text/css\" href='./lib/my_toc/main.css' media=\"screen\" />\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import division\n",
    "from import_file import *\n",
    "load_libs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ipath= \"C:\\Users\\Administrator\\Desktop\\科研风速数据资料\\美国时刻风速数据\\上海\\虹桥\\\\9705626661750dat.txt\"\n",
    "# For Shanghai\n",
    "# df.drop(['NCDC', 'Date','I', 'Type', 'Q', 'Q.1'], 1, inplace=True)\n",
    "# df.rename(columns={'HrMn':'date','Dir': 'dir', 'Spd':'speed'}, inplace=True)\n",
    "\n",
    "# ipath = './boscombe_down/3466726903106dat.txt'\n",
    "ipath = './ciampino/6240476818161dat.txt'\n",
    "# ipath = 'tiree.txt'\n",
    "# ipath= \"marham.txt\"\n",
    "uipath = unicode(ipath , \"utf8\")\n",
    "file2 = open(uipath)\n",
    "df = pd.read_csv(uipath,header=0, skipinitialspace=True)\n",
    "df.drop(['USAF', 'NCDC', 'I','Type' ,'QCP','Q','Q.1','I.1','Unnamed: 12'], 1,inplace=True)\n",
    "df.rename(columns={'Date':'date','Dir': 'dir', 'Spd':'speed'}, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select year 1945-2014, dir < 999, speed<999\n",
    "df = df[(df['dir'] < 999) & (df['speed'] < 999)& (df['date'] < 20150000) ]\n",
    "df.rename(columns={'speed':'speed_mps'}, inplace=True)\n",
    "df['speed']=df['speed_mps']\n",
    "df.index= df['date']\n",
    "df['speed'].plot(legend=True,figsize=(10,4), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Selection\n",
    "# Marham, date >1973\n",
    "# Ciampino, date： 1973~2014\n",
    "if \"ciampino\" not in ipath: \n",
    "    df = df[ (df['date'] > 19730000) & (df['date'] < 20150000)]\n",
    "    df = df[df['HrMn'] % 100 <= 0.1]\n",
    "else: \n",
    "    # For Roma Ciampino\n",
    "    df = df[ (df['date'] > 19720000) & (df['date'] < 20150000)]\n",
    "    df = df[(df['HrMn'] % 100 == 15)|(df['HrMn'] % 100 == 45)|(df['HrMn'] % 100 == 20)|(df['HrMn'] % 100 == 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using speed unit in knot instead of m/s\n",
    "df['speed']=df['speed_mps']*1.943845\n",
    "# need more elaboration, some is not near an integer\n",
    "df['speed'] =  df['speed'].apply(lambda x: int(round(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['incre'] = df.speed.diff(1)\n",
    "df['incre'].fillna(0)\n",
    "df['incre_reverse'] = df.speed.diff(-1)\n",
    "df['incre_reverse'].fillna(0)\n",
    "print df.sort('speed',ascending=False).head(20)\n",
    "bins=np.arange(-15, 15 + 1, 1)\n",
    "df['incre'].hist(bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple Artefacts Handling\n",
    "df =  df[ (df['incre'] < 20)&(df['incre_reverse'] < 20)]\n",
    "df = df[df['dir'] % 10 <= 0.1]\n",
    "df = df[df['speed'] >= 0.1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Simple Aretefacts Hnadling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the max speed\n",
    "print df.sort('speed',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensure data sampled equally\n",
    "print df['HrMn'].value_counts()\n",
    "bins=np.arange(min(df.HrMn), max(df.HrMn) + 100, 50)\n",
    "df['HrMn'].hist(bins=bins, alpha=0.5,figsize=(15, 6))\n",
    "plt.suptitle('Data Sampling Time Distribution', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins=np.arange(min(df.speed), max(df.speed) + 1, 1)\n",
    "df['speed'].hist(bins=bins, alpha=0.5,figsize=(15, 6))\n",
    "plt.suptitle('Overall Speed Distribution', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins=np.arange(min(df.dir), max(df.dir) + 10, 5)\n",
    "df['dir'].hist(bins=bins, alpha=0.3,figsize=(15, 6))\n",
    "plt.suptitle('Overall Direction Distribution', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['speed'].plot(legend=True,figsize=(10,4), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Comparison between year < 2000, and > 2000, looking for: \n",
    "# 1. Odd Even Bias\n",
    "# 2. Time Shift of Wind Speed Distribution\n",
    "df_temp = df[df['date'] < 20000000]\n",
    "bins = np.arange(min(df_temp.speed), max(df_temp.speed) + 1, 1)\n",
    "df_temp['speed'].hist(bins=bins,alpha = 0.5,figsize=(15, 6))\n",
    "\n",
    "df_temp = df[df['date'] > 20000000]\n",
    "bins = np.arange(min(df_temp.speed), max(df_temp.speed) + 1, 1)\n",
    "df_temp['speed'].hist(bins=bins, alpha = 0.5,figsize=(15, 6))\n",
    "\n",
    "plt.xlabel(\"Speed\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.suptitle('Comparison between year < 2000, and > 2000', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the time shift of speed and degree distribution, and odd-even bias\n",
    "def check_time_shift(df):\n",
    "    for start_time in xrange(19750000,20150000,50000):\n",
    "        end_time = start_time + 50000 \n",
    "        sub_df = df[ (df['date'] >= start_time) & (df['date'] < end_time)]\n",
    "        fig = plt.figure()\n",
    "        bins = np.arange(min(sub_df.speed), max(sub_df.speed) + 1, 1)\n",
    "        sub_df['speed'].hist(bins=bins)\n",
    "        fig.suptitle(start_time)\n",
    "\n",
    "    for start_time in xrange(19750000,20150000,50000):\n",
    "        end_time = start_time + 50000 \n",
    "        sub_df = df[ (df['date'] >= start_time) & (df['date'] < end_time)]\n",
    "        bins=np.arange(min(sub_df.dir), max(sub_df.dir) + 10, 5)\n",
    "        fig = plt.figure()\n",
    "        sub_df['dir'].hist(bins=bins, alpha=0.3,figsize=(15, 6))\n",
    "        fig.suptitle(start_time)\n",
    "    \n",
    "# check_time_shift(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-select time range after looking at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if \"ciampino\" in ipath: \n",
    "    # For Ciampino\n",
    "    df = df[ (df['date'] >= 20100000) & (df['date'] < 20150000)]\n",
    "elif \"marham\" in ipath:\n",
    "    # For Marham\n",
    "    # speed still suffers from odd-even bias\n",
    "    df = df[ (df['date'] >= 20100000) & (df['date'] < 20150000)]\n",
    "else: \n",
    "    # For Tiree, non is stable\n",
    "    df = df[ (df['date'] > 19720000) & (df['date'] < 20150000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from windrose import WindroseAxes\n",
    "\n",
    "df.dir_windrose = df.dir\n",
    "# 90 degree is in east\n",
    "ax = WindroseAxes.from_ax()\n",
    "ax.bar(df.dir_windrose, df.speed, normed=True, opening=0.8, edgecolor='white', nsector=36)\n",
    "ax.set_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from windrose import WindAxes\n",
    "ax = WindAxes.from_ax()\n",
    "bins=np.arange(min(df.speed), max(df.speed) + 1, 1)\n",
    "ax, params = ax.pdf(df.speed, bins = bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print params\n",
    "weibull_params = sp.stats.exponweib.fit(df.speed, floc=0, f0=1)\n",
    "print weibull_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = df.speed\n",
    "ecdf = sm.distributions.ECDF(sample)\n",
    "\n",
    "x = np.linspace(min(sample), max(sample))\n",
    "y = ecdf(x)\n",
    "plt.plot(np.log(x), np.log(-np.log(1-y)),'o')\n",
    "\n",
    "x = np.linspace(min(sample), max(sample))\n",
    "w_scale = weibull_params[1]\n",
    "c_shape = weibull_params[3]\n",
    "qz=np.exp(-(x/c_shape)**w_scale)\n",
    "plt.plot(np.log(x), np.log(-np.log(qz)),'-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert from windrose system to polar system\n",
    "df['dir'] = 90-df.dir\n",
    "\n",
    "df['dir'] = df['dir'].apply(lambda x: x + 360 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Randomize angle\n",
    "def randomize_angle(df):\n",
    "    df['random_angle_incre'] = 0\n",
    "    df['random_angle_incre'] = df['random_angle_incre'].apply(lambda x: np.random.uniform(-5,5))\n",
    "    df['dir_ran']=df['dir']+df['random_angle_incre']\n",
    "    bins=np.arange(min(df.dir_ran), max(df.dir_ran) + 1, 1)\n",
    "\n",
    "    df['dir_ran']= df['dir_ran'].apply(lambda x: x + 360 if x < 0 else x)\n",
    "    df['dir_ran']= df['dir_ran'].apply(lambda x: x - 360 if x > 360 else x)\n",
    "    df['dir'].hist(bins=bins, alpha=0.5,figsize=(15, 6))\n",
    "    df['dir_ran'].hist(bins=bins, alpha=0.5,figsize=(15, 6))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomize the angle degree, to form a better KDE estimation\n",
    "df = randomize_angle(df)\n",
    "df['dir']=df['dir_ran']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "df['phi'] = df['dir'] - alpha\n",
    "df['u'] = df['speed'] * np.cos(df['phi'] * pi / 180.0)\n",
    "df['v'] = df['speed'] * np.sin(df['phi'] * pi / 180.0)\n",
    "df['x']=df.u\n",
    "df['y']=df.v\n",
    "fig, ax = plt.subplots(figsize=(8, 8), dpi=80)\n",
    "ax.set_aspect('equal')\n",
    "df.plot(kind='scatter', x='x', y='y', alpha=0.35, ax=ax)\n",
    "print np.mean(df.x), np.mean(df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if there is any missing dir \n",
    "if 'dir_ran' not in df.columns:\n",
    "    print df['dir'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive OEN Estimation (Single Gaussian)\n",
    "Optional, only for demonstration purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_single_OEN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab \n",
    "import scipy.stats as stats\n",
    "def cor_of_alpha(alpha):\n",
    "    df['phi'] = df['dir'] - alpha\n",
    "    df['u'] = df['speed'] * np.cos(df['phi'] * pi / 180.0)\n",
    "    df['v'] = df['speed'] * np.sin(df['phi'] * pi / 180.0)\n",
    "    cor = sp.stats.pearsonr(df['u'],df['v'])\n",
    "    return cor[0]\n",
    "\n",
    "# Try plot alpha - cor\n",
    "def plot_cor():\n",
    "    cors = []\n",
    "    for alpha in np.arange(0,180,10):\n",
    "        cor = cor_of_alpha(alpha)\n",
    "        std_u = np.std(df.u)\n",
    "        std_v = np.std(df.v)\n",
    "        comb = [alpha, cor, std_u, std_v]\n",
    "        cors.append(comb)\n",
    "        print comb\n",
    "\n",
    "    plt.scatter(zip(*cors)[0], zip(*cors)[1]) # plot rotation-correlation\n",
    "    plt.title('Rotation angle - Correlation')\n",
    "    pylab.show()\n",
    "    \n",
    "    pylab.plot(zip(*cors)[0], zip(*cors)[2]) # plot rotation-std_u\n",
    "    pylab.plot(zip(*cors)[0], zip(*cors)[3]) # plot rotation-std_v\n",
    "    plt.title('Rotation angle - std')\n",
    "    pylab.show()\n",
    "    \n",
    "if run_single_OEN: plot_cor() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rotate_for_lowest_correlation(df):\n",
    "    # Find the desired alpha for lowest correlation between u,v\n",
    "    # alpha is the rotation angle for u-v panel\n",
    "    alpha = sp.optimize.brentq(cor_of_alpha, 0, 90)\n",
    "    df['phi'] = df['dir'] - alpha\n",
    "    df['u'] = df['speed'] * np.cos(df['phi'] * pi / 180.0)\n",
    "    df['v'] = df['speed'] * np.sin(df['phi'] * pi / 180.0)\n",
    "    cor = sp.stats.pearsonr(df.u,df.v)\n",
    "    print 'rotation angle and corresponding correlation: \\n', alpha, cor\n",
    "    return df  # return the dataset that has rorated u,v value\n",
    "\n",
    "if run_single_OEN: df = rotate_for_lowest_correlation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare u,v with normal distrubution\n",
    "## P-P plot, vs Q-Q plot, should be q-q\n",
    "def plot_against_normal_distribution(df):\n",
    "    mean,std = np.mean(df.u),np.std(df.u)\n",
    "    df['u_norm']=df['u'].apply(lambda x: (x-mean)/std)\n",
    "    print 'u mean and std:', mean, std\n",
    "\n",
    "    mean,std = np.mean(df.v),np.std(df.v)\n",
    "    df['v_norm']=df['v'].apply(lambda x: (x-mean)/std)\n",
    "    print 'v mean and std:', mean, std\n",
    "\n",
    "    stats.probplot(df.u_norm, dist=\"norm\", plot=pylab)\n",
    "    stats.probplot(df.v_norm, dist=\"norm\", plot=pylab)\n",
    "\n",
    "    pylab.show()\n",
    "    \n",
    "if run_single_OEN: plot_against_normal_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "from math import *\n",
    "\n",
    "def calculate_the_probability_distribution_of_windspeed(df):\n",
    "    u,v = np.mean(df.u), np.mean(df.v)\n",
    "    sigu, sigv = np.std(df.u), np.std(df.v)\n",
    "    U = sqrt((u)**2 + (v)**2) # the R value of the centre of the ellipse, in polar coords\n",
    "    phi = atan(u/v) # the angle of the centre of the elliplse, in polar coords\n",
    "\n",
    "    def f(V,theta):\n",
    "        return exp(-1/2* (( (V*cos(theta)-U*cos(phi)) /sigu)**2 + ((V*sin(theta)-U*sin(phi)) /sigv)**2))/(2*np.pi*sigu*sigv)*V\n",
    "\n",
    "    # x is the speed, y is the probalility\n",
    "    x_vals = np.linspace(0,50.)\n",
    "    y_vals =[integrate.nquad(f, [[0, x_val],[0, 2*np.pi]]) for x_val in x_vals]\n",
    "    return x_vals,y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_comparison(df):\n",
    "    sample = df.speed\n",
    "    ecdf = sm.distributions.ECDF(sample)\n",
    "\n",
    "    # Empirical distribution, plot points\n",
    "    x = np.linspace(min(sample), max(sample))\n",
    "    y = ecdf(x)\n",
    "    plt.plot(np.log(x), np.log(-np.log(1-y)),'o')\n",
    "\n",
    "    # Weibull distribution\n",
    "    x = np.linspace(min(sample), max(sample))\n",
    "    w_scale = weibull_params[1] # The Weibull need previous code fitting \n",
    "    c_shape = weibull_params[3]\n",
    "    qz=np.exp(-(x/c_shape)**w_scale)\n",
    "    plt.plot(np.log(x), np.log(-np.log(qz)),'-')\n",
    "\n",
    "    # OEN distribution\n",
    "    x, y_ = x_vals, y_vals\n",
    "    y = np.array(zip(*y_)[0])\n",
    "    plt.plot(np.log(x), np.log(-np.log(1-y)),'-')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "if run_single_OEN:\n",
    "    x_vals,y_vals = calculate_the_probability_distribution_of_windspeed(df)\n",
    "    plot_comparison(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single OEN Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_single_OEN_fitting(df):\n",
    "    plot_cor()\n",
    "    df = rotate_for_lowest_correlation(df)\n",
    "    plot_against_normal_distribution(df)\n",
    "    x_vals,y_vals = calculate_the_probability_distribution_of_windspeed(df)\n",
    "    plot_comparison(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Create Input, speed_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# speed_set = np.array(zip(-df.x, -df.y)) # Adjust the direction to match for Cook's paper\n",
    "speed_set = np.array(zip(df.x, df.y))\n",
    "speed_angle_set = np.array(zip(df.speed, df.dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = speed_set\n",
    "from sklearn.neighbors import KernelDensity\n",
    "kde = KernelDensity(bandwidth=1).fit(sample) # need to consider the bandwidth for different sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot jPDF\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from itertools import product\n",
    "\n",
    "def plot_3d_prob_density(X,Y,Z):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    surf = ax.plot_surface(\n",
    "        X, Y, Z,rstride=1, cstride=1, cmap='jet',\n",
    "                       linewidth=0, antialiased=False)\n",
    "    return plt.show()\n",
    "\n",
    "def plot_2d_prob_density(X,Y,Z):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), dpi=80)\n",
    "    ax.set_aspect('equal')\n",
    "    # For docs, see `help(plt.contour)`\n",
    "    return plt.contourf(X, Y, Z, 10, alpha=.75, cmap='jet')  \n",
    "\n",
    "X = Y = np.arange(-30, 31, 1)\n",
    "XX,YY=np.meshgrid(X,Y)\n",
    "coords=np.array((XX.ravel(), YY.ravel())).T  \n",
    "Z = np.exp(kde.score_samples(coords)).reshape(len(X),len(Y))\n",
    "\n",
    "plot_3d_prob_density(X,Y,Z)\n",
    "\n",
    "plot_2d_prob_density(X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can get the result, but speed is very slow\n",
    "def f(x,y):\n",
    "    # exp to turn log probabilty into normal\n",
    "    return exp(kde.score_samples([x,y]))\n",
    "\n",
    "# Check for the corretness of the method, should ~1\n",
    "# integrate.nquad(f, [[-50, 50],[-50, 50]])\n",
    "\n",
    "# Query for the prob of a certain point\n",
    "exp(kde.score_samples([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GMM Estimation, using EM algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample= speed_set\n",
    "\n",
    "# fit a Gaussian Mixture Model with two components\n",
    "clf = mixture.GMM(n_components=3, covariance_type='full')\n",
    "clf.fit(sample)\n",
    "\n",
    "print clf.converged_\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    print clf.weights_[i], clf.means_[i], clf.covars_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "# Check pdf\n",
    "def f(x,y):\n",
    "    # exp to turn log probabilty into normal\n",
    "    return exp(clf.score([[x,y]]))\n",
    "# integrate.nquad(f, [[-50, 50],[-50, 50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how to write the for loop?\n",
    "fig, ax = plt.subplots()\n",
    "for i, color in enumerate('rgb'):\n",
    "    # eigenvalues, and eigen vector\n",
    "    v, w = np.linalg.eigh(clf._get_covars()[i][:2, :2])\n",
    "\n",
    "    u1 = w[0] / np.linalg.norm(w[0])\n",
    "    angle = np.arctan2(u1[1], u1[0])\n",
    "    angle = 180 * angle / np.pi\n",
    "    # angle, mean, eigenvalues, \n",
    "    print angle, clf.means_[i], v\n",
    "    # half width stands for std value\n",
    "    ell = mpl.patches.Ellipse(xy=clf.means_[i], width=2*sqrt(v[0]), height=2*sqrt(v[1]), angle = angle, color=color)\n",
    "    ell.set_alpha(0.5)\n",
    "    ax.add_patch(ell)\n",
    "    \n",
    "# plt.scatter(sample[:, 0], sample[:, 1],  marker='+', alpha=0.5, color = 'y')\n",
    "ax.set_aspect('equal')\n",
    "ax.autoscale()\n",
    "plt.draw() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample= speed_set\n",
    "# plot sample point\n",
    "plt.scatter(sample[:, 0], sample[:, 1], marker='+', alpha=0.5)\n",
    "\n",
    "x = y = np.linspace(-50, 50)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "Z = -clf.score_samples(XX)[0]\n",
    "Z = Z.reshape(X.shape)\n",
    "\n",
    "CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=10.0),\n",
    "                 levels=np.logspace(0, 1, 10))\n",
    "CB = plt.colorbar(CS, shrink=0.8, extend='both')\n",
    "plt.xlim((-50,50))\n",
    "plt.ylim((-50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = Y = np.arange(-30, 31, 1)\n",
    "XX,YY=np.meshgrid(X,Y)\n",
    "coords=np.array((XX.ravel(), YY.ravel())).T  \n",
    "Z = np.exp(clf.score_samples(coords)[0]).reshape(XX.shape)\n",
    "    \n",
    "plot_3d_prob_density(X,Y,Z)\n",
    "\n",
    "plot_2d_prob_density(X,Y,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM, EM VS. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel_array = []\n",
    "for i in np.arange(-30, 31, 1):\n",
    "    for j in np.arange(-30, 31, 1):\n",
    "        panel_array.append([i,j])\n",
    "\n",
    "points = panel_array\n",
    "gmm_pdf_result = np.exp(clf.score_samples(points)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kde_result = np.exp(kde.score_samples(points))\n",
    "kde_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_point = [0,0]\n",
    "print exp(kde.score_samples(test_point))\n",
    "print exp(clf.score_samples(test_point)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE & R Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_array = np.power(gmm_pdf_result - kde_result,2)\n",
    "rmse = np.sqrt(np.average(error_array))\n",
    "print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# R square measure:\n",
    "# https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "y_mean = np.mean(kde_result)\n",
    "SS_tot = np.power(kde_result - y_mean,2)\n",
    "SS_tot_avg = np.average(SS_tot)\n",
    "print SS_tot_avg\n",
    "\n",
    "# The original value is result.fun is log of rmse\n",
    "SS_res_avg = np.average(error_array)\n",
    "print SS_res_avg\n",
    "\n",
    "R_square = 1 - SS_res_avg/SS_tot_avg \n",
    "print R_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This calculation speed is very slow\n",
    "def f(V,theta):\n",
    "    return exp(clf.score([[V*cos(theta),V*sin(theta)]]))*V\n",
    "# integrate.nquad(f, [[0, inf],[0, 2*np.pi]])\n",
    "\n",
    "x_vals_OEN3_EM = np.linspace(0,50)\n",
    "y_vals_OEN3_EM =[integrate.nquad(f, [[0, x_val],[0, 2*np.pi]]) for x_val in x_vals_OEN3_EM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = df.speed\n",
    "ecdf = sm.distributions.ECDF(sample)\n",
    "\n",
    "# Plot points, with empirical distribution\n",
    "x = np.linspace(min(sample), max(sample))\n",
    "y = ecdf(x)\n",
    "plt.plot(np.log(x), np.log(-np.log(1-y)),'o')\n",
    "\n",
    "# Weibull distribution\n",
    "x = np.linspace(min(sample), max(sample))\n",
    "w_scale = weibull_params[1]\n",
    "c_shape = weibull_params[3]\n",
    "qz=np.exp(-(x/c_shape)**w_scale)\n",
    "plt.plot(np.log(x), np.log(-np.log(qz)),'-')\n",
    "\n",
    "# OEN3 distribution\n",
    "x, y_ = x_vals_OEN3_EM, y_vals_OEN3_EM\n",
    "y = np.array(zip(*y_)[0])\n",
    "plt.plot(np.log(x), np.log(-np.log(1-y)),'-', color = 'y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Calculate angle distribution\n",
    "# def f(V,theta):\n",
    "#     return exp(clf.score([[V*cos(theta),V*sin(theta)]]))*V\n",
    "\n",
    "# integrate.nquad(f, [[0, inf],[0, 2*np.pi]])\n",
    "\n",
    "# x_vals = np.linspace(0,2*np.pi, num=36)\n",
    "# y_vals =[integrate.nquad(f, [[0, inf],[x_val, x_val+np.pi/18]]) for x_val in x_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x, y_ = x_vals, y_vals\n",
    "# y = np.array(zip(*y_)[0])*len(sample)\n",
    "# bins=np.arange(min(df.dir), max(df.dir) + 1, 1)\n",
    "# df['dir'].hist(bins=bins, alpha=0.5,figsize=(15, 6))\n",
    "# plt.plot(x/np.pi*180, y,'-', color='black')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Least Square Prob Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "if not kde:\n",
    "    sample = speed_set\n",
    "    kde = KernelDensity(bandwidth=1.0).fit(sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel_array = []\n",
    "for i in np.arange(-30, 31, 1):\n",
    "    for j in np.arange(-30, 31, 1):\n",
    "        panel_array.append([i,j])\n",
    "\n",
    "sample = panel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# very slow if the dataset is too large, e.g. 100,000\n",
    "if not kde_result.all():\n",
    "    kde_result = np.exp(kde.score_samples(sample))\n",
    "kde_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(kde_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmm_em_result = []\n",
    "gmm_em_result.extend(clf.weights_[0:3])\n",
    "for i in [0,1,2]:\n",
    "    meanx,meany=clf.means_[i].tolist()\n",
    "    sigx,sigy = np.sqrt(clf.covars_ [i][0,0]), np.sqrt(clf.covars_ [i][1,1])\n",
    "    rho = clf.covars_ [i][0,1]/(sigx*sigy)\n",
    "    gmm_em_result.extend([meanx,meany, sigx,sigy,rho])\n",
    "    print meanx,meany, sigx,sigy,rho\n",
    "    \n",
    "print gmm_em_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = sample\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def create_gaussian_2d(meanx,meany,sigx,sigy,rho):\n",
    "    sigxy = rho*sigx*sigy\n",
    "    return multivariate_normal(mean=[meanx,meany], cov=[[sigx**2,sigxy],[sigxy,sigy**2]], allow_singular=True)\n",
    "\n",
    "def square_error(x0, log_mode = False):\n",
    "    f1,f2,f3,\\\n",
    "    u1,v1,sigu1,sigv1,rho1, \\\n",
    "    u2,v2,sigu2,sigv2,rho2, \\\n",
    "    u3,v3,sigu3,sigv3,rho3 = x0\n",
    "    # 1. Generate Mixed Gaussian Model  \n",
    "    g1 = create_gaussian_2d(u1,v1,sigu1,sigv1,rho1)   \n",
    "    g2 = create_gaussian_2d(u2,v2,sigu2,sigv2,rho2)\n",
    "    g3 = create_gaussian_2d(u3,v3,sigu3,sigv3,rho3) \n",
    "    def mixed_model(points):\n",
    "        return f1*g1.pdf(points)+f2*g2.pdf(points)+f3*g3.pdf(points)\n",
    "    # 2. Calculate the sum of square error\n",
    "    # kde returns log prob, so need to convert it\n",
    "    if log_mode:\n",
    "        error_array = np.power(np.log(mixed_model(points)) - np.log(kde_result),2)\n",
    "        mse = np.average(error_array)\n",
    "        rmse = np.sqrt(mse)\n",
    "        result = rmse\n",
    "    else:\n",
    "#         error_array = np.power(mixed_model(points) - cook_kde,2)\n",
    "        error_array = np.power(mixed_model(points) - kde_result,2)\n",
    "        mse = np.average(error_array)\n",
    "        rmse = np.sqrt(mse)\n",
    "        result = np.log(rmse)\n",
    "    return result\n",
    "    # The returned number seems too small, how to deal with it?   \n",
    "\n",
    "cons = [{'type': 'eq', 'fun': lambda x: -x[0] - x[1] - x[2]+ 1}]\n",
    "bonds = [(0., 0.99),(0., 0.99),(0., 0.99),\n",
    "            (-30, 30),(-30, 30),(0., 30),(0., 30),(-0.99, 0.99),\n",
    "            (-30, 30),(-30, 30),(0., 30),(0., 30),(-0.99, 0.99),\n",
    "            (-30, 30),(-30, 30),(0., 30),(0., 30),(-0.99, 0.99),]\n",
    "\n",
    "# from GMM,EM \n",
    "x0 = gmm_em_result\n",
    "\n",
    "result = sp.optimize.minimize(\n",
    "    square_error,\n",
    "    x0,\n",
    "    method = 'SLSQP', \n",
    "    bounds = bonds,\n",
    "    constraints=cons,\n",
    "    tol = 0.000000000001,\n",
    "    options = {\"maxiter\": 500})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRMSE VS. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Least Root Mean Square Error result\n",
    "exp(result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RMSE / Mode\n",
    "print exp(result.fun)/np.max(kde_result)\n",
    "print exp(result.fun)/np.mean(kde_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# R square measure:\n",
    "# https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "\n",
    "y_mean = np.mean(kde_result)\n",
    "SS_tot = np.power(kde_result - y_mean,2)\n",
    "SS_tot_avg = np.average(SS_tot)\n",
    "print SS_tot_avg\n",
    "\n",
    "# The original value is result.fun is log of rmse\n",
    "SS_res_avg = np.square(exp(result.fun))\n",
    "print SS_res_avg\n",
    "\n",
    "R_square = 1 - SS_res_avg/SS_tot_avg \n",
    "print R_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.mean(cook_kde)/np.mean(kde_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1,f2, f3,\\\n",
    "u1,v1,sigu1,sigv1,rho1, \\\n",
    "u2,v2,sigu2,sigv2,rho2, \\\n",
    "u3,v3,sigu3,sigv3,rho3 = result.x\n",
    "\n",
    "g1 = f1,u1,v1,sigu1,sigv1,rho1\n",
    "g2 = f2,u2,v2,sigu2,sigv2,rho2\n",
    "g3 = f3,u3,v3,sigu3,sigv3,rho3\n",
    "gmm = [g1,g2,g3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for g in gmm:\n",
    "    xy_mean = np.matrix([g[1],g[2]])\n",
    "    sigx, sigy, sigxy = g[3],g[4],g[5]*g[3]*g[4]\n",
    "    cov_matrix = np.matrix([[sigx**2, sigxy], [sigxy, sigy**2]])\n",
    "\n",
    "    # eigenvalues, and eigen vector\n",
    "    w, v = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    uu = v[0] / np.linalg.norm(v[0])\n",
    "    angle_arc = -(np.arctan2(uu[0,1], uu[0,0])+np.pi)\n",
    "    # rorate angle, counter clock wise\n",
    "    angle = - 180 * angle_arc / np.pi\n",
    "    \n",
    "    transform_matrix = np.matrix([[np.cos(angle_arc ), -np.sin(angle_arc )], [np.sin(angle_arc ), np.cos(angle_arc )]])\n",
    "    xy_mean_in_uv = transform_matrix * xy_mean.T\n",
    "    \n",
    "    # print fraction, rotation agnle, u v mean(in standalone panel), std\n",
    "    print g[0], xy_mean_in_uv, np.sqrt(w), angle, \n",
    "    print ''\n",
    "\n",
    "    ell = mpl.patches.Ellipse(xy=xy_mean.T, width=2*sqrt(w[0]), height=2*sqrt(w[1]), angle = angle)\n",
    "    ell.set_alpha(0.5)\n",
    "    ax.add_patch(ell)\n",
    "\n",
    "\n",
    "ax.autoscale()\n",
    "ax.set_aspect('equal')\n",
    "plt.draw() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot probability density \n",
    "g1 = create_gaussian_2d(u1,v1,sigu1,sigv1,rho1)   \n",
    "g2 = create_gaussian_2d(u2,v2,sigu2,sigv2,rho2)\n",
    "g3 = create_gaussian_2d(u3,v3,sigu3,sigv3,rho3) \n",
    "def mixed_model_pdf(points):\n",
    "    return f1*g1.pdf(points)+f2*g2.pdf(points)+f3*g3.pdf(points)\n",
    "\n",
    "X = Y = np.arange(-30, 31, 1)\n",
    "XX,YY=np.meshgrid(X,Y)\n",
    "coords=np.array((XX.ravel(), YY.ravel())).T  \n",
    "Z = np.exp(mixed_model_pdf(coords)).reshape(XX.shape)\n",
    "    \n",
    "plot_3d_prob_density(X,Y,Z)\n",
    "\n",
    "plot_2d_prob_density(X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(V,theta):\n",
    "    return (mixed_model_pdf([[V*cos(theta),V*sin(theta)]]))*V\n",
    "\n",
    "x_vals_OEN3_LMSE  = np.linspace(0,50)\n",
    "y_vals_OEN3_LMSE =[integrate.nquad(f, [[0, x_val],[0, 2*np.pi]]) for x_val in x_vals_OEN3_LMSE ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(V,theta):\n",
    "    return np.exp(kde.score_samples([[V*cos(theta),V*sin(theta)]]))*V\n",
    "# integrate.nquad(f, [[0, 50],[0, 2*np.pi]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot v-p\n",
    "sample = df.speed\n",
    "ecdf = sm.distributions.ECDF(sample)\n",
    "\n",
    "# Plot points, with empirical distribution\n",
    "x = np.linspace(min(sample), max(sample))\n",
    "y = ecdf(x)\n",
    "plt.plot(np.log(x), np.log(-np.log(1-y)),'o')\n",
    "\n",
    "# OEN3 distribution, EM\n",
    "x, y_ = x_vals_OEN3_EM, y_vals_OEN3_EM\n",
    "y = np.array(zip(*y_)[0])\n",
    "plt.plot(np.log(x), np.log(-np.log(1-y)),'-', color = 'y')\n",
    "\n",
    "# OEN3 distribution, LMSE\n",
    "x, y_ = x_vals_OEN3_LMSE, y_vals_OEN3_LMSE\n",
    "y = np.array(zip(*y_)[0])\n",
    "plt.plot(np.log(x), np.log(-np.log(1-y)),'-', color = 'r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(V,theta):\n",
    "    return (mixed_model_pdf([[V*cos(theta),V*sin(theta)]]))*V\n",
    "\n",
    "# Check, should ~1\n",
    "# integrate.nquad(f, [[0, inf],[0, 2*np.pi]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Angle Distribution\n",
    "x_vals = np.linspace(0,2*np.pi, num=36)\n",
    "y_vals =[integrate.nquad(f, [[0, inf],[x_val, x_val+np.pi/18]]) for x_val in x_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y_ = x_vals, y_vals\n",
    "# 1. integrate.nquad returns 2 vaule, result, abserr. Need to abstract the first to plot\n",
    "# 2. * length of data size, to adjust the plot space\n",
    "y = np.array(zip(*y_)[0])*len(df['dir']) \n",
    "\n",
    "bins=np.arange(0, 360 + 1, 10)\n",
    "df['dir'].hist(bins=bins, alpha=0.5,figsize=(15, 6))\n",
    "\n",
    "plt.plot(x/np.pi*180, y,'-', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Speed Distribution\n",
    "x_vals = np.arange(0, 35, 1)\n",
    "y_vals =[integrate.nquad(f, [[x_val, x_val+1],[0, 2*np.pi]]) for x_val in x_vals]\n",
    "\n",
    "x, y_ = x_vals, y_vals\n",
    "y = np.array(zip(*y_)[0])*len(df.speed)\n",
    "\n",
    "bins=np.arange(min(df.speed), max(df.speed) + 1, 1)\n",
    "df['speed'].hist(bins=bins, alpha=0.5,figsize=(15, 6))\n",
    "\n",
    "plt.plot(x, y,'-', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['speed'].value_counts().sort_index()\n",
    "# how to get the value out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE From Cook, Ciampino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# points\n",
    "# kde results should from [-30, -30], [-30, -29],[-30, -28] to [30,30]\n",
    "kde_file = 'cook_kde.csv'\n",
    "temp_matrix = np.loadtxt(open(kde_file,\"rb\"),delimiter=\",\",skiprows=1)\n",
    "temp_matrix2 = temp_matrix.reshape(-1)\n",
    "cook_kde = temp_matrix2\n",
    "cook_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_array = np.power(kde_result - cook_kde,2)\n",
    "mse = np.average(error_array)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OEN3 from Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal, norm   \n",
    "\n",
    "def create_rotate_norm_dist(meanx,meany,sigx,sigy,angle):\n",
    "    # angle degree, from u,v to x,y, counter-clockwise\n",
    "    alpha = angle\n",
    "    alpha_arc = alpha * pi / 180.0\n",
    "    transform_matrix = np.matrix([[np.cos(alpha_arc), -np.sin(alpha_arc)], [np.sin(alpha_arc), np.cos(alpha_arc)]])\n",
    "    cov_matrix = np.matrix([[sigx**2, 0], [0, sigy**2]])\n",
    "    # cov_matrix\n",
    "    cov_trans = transform_matrix * cov_matrix * transform_matrix.T\n",
    "    # need to converte by .tolist()[0]\n",
    "    norm_mean = np.matrix.dot(transform_matrix,np.array([meanx,meany])).tolist()[0]\n",
    "    norm_rotate = multivariate_normal(mean=norm_mean, cov=cov_trans, allow_singular=True)\n",
    "    \n",
    "    return norm_rotate\n",
    "\n",
    "# need to change the direction of x,y of Cook, to comply with the standard in this program\n",
    "g1 = create_rotate_norm_dist(0.0565402,3.5586487,5.809,9.237,10.511)\n",
    "g2 = create_rotate_norm_dist(4.315,-0.407,3.002,4.173,75.193)\n",
    "g3 = create_rotate_norm_dist(-0.491,-2.777,1.979,2.571,-25.358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# format to mean, std, rho\n",
    "for g in [g1,g2,g3]:\n",
    "    sigx,sigy = np.sqrt(g.cov[0,0]), np.sqrt(g.cov[1,1])\n",
    "    rho = g.cov[0,1]/(sigx*sigy)\n",
    "    print g.mean, sigx,sigy,rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot Cook's ellipses results.\n",
    "# Input from Cook's LMSE result, \n",
    "# mean_u, mean_v, std_u, std_v, rotation_angle\n",
    "gc1 = [0.0565402,3.5586487,5.809,9.237,10.511]\n",
    "gc2 = [4.315,-0.407,3.002,4.173,75.193]\n",
    "gc3 = [-0.491,-2.777,1.979,2.571,-25.358]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for g in [gc1,gc2,gc3]:\n",
    "    xy_mean_in_uv = np.matrix([g[0],g[1]])\n",
    "    std_x, std_y = g[2],g[3]\n",
    "    \n",
    "    angle = g[4]\n",
    "    angle_arc = angle * pi / 180.0\n",
    "    transform_matrix = np.matrix([[np.cos(angle_arc), -np.sin(angle_arc)], [np.sin(angle_arc), np.cos(angle_arc)]])\n",
    "    xy_mean = transform_matrix * xy_mean_in_uv.T\n",
    "    \n",
    "    print xy_mean, g[2],g[3], angle\n",
    "    \n",
    "    ell = mpl.patches.Ellipse(xy=xy_mean, width=2*g[2], height=2*g[3], angle = angle)\n",
    "    ell.set_alpha(0.5)\n",
    "    ax.add_patch(ell)\n",
    "\n",
    "ax.autoscale()\n",
    "ax.set_aspect('equal')\n",
    "plt.draw() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g=g3\n",
    "# use np.matrix, not np.array\n",
    "xy_mean = np.matrix([g.mean[0],g.mean[1]])\n",
    "cov_matrix = g.cov\n",
    "\n",
    "# eigenvalues, and eigen vector\n",
    "w, v = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "uu = v[0] / np.linalg.norm(v[0])\n",
    "angle_arc = -(np.arctan2(uu[1], uu[0])+np.pi)\n",
    "# # rorate angle, counter clock wise\n",
    "angle = - 180 * angle_arc / np.pi\n",
    "\n",
    "transform_matrix = np.matrix([[np.cos(angle_arc ), -np.sin(angle_arc )], [np.sin(angle_arc ), np.cos(angle_arc )]])\n",
    "xy_mean_in_uv = transform_matrix * xy_mean.T\n",
    "\n",
    "# # print fraction, rotation agnle, u v mean(in standalone panel), std\n",
    "print xy_mean_in_uv, np.sqrt(w),angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1, f2 = 0.415, 0.298\n",
    "def mixed_model_pdf(points):\n",
    "    return f1*g1.pdf(points)+f2*g2.pdf(points)+(1-f1-f2)*g3.pdf(points)\n",
    "\n",
    "X = Y = np.arange(-30, 31, 1)\n",
    "XX,YY=np.meshgrid(X,Y)\n",
    "coords=np.array((XX.ravel(), YY.ravel())).T \n",
    "Z = mixed_model_pdf(coords).reshape(XX.shape)\n",
    "\n",
    "plot_3d_prob_density(X,Y,Z)\n",
    "\n",
    "plot_2d_prob_density(X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# points is [-30,30]\n",
    "error_array = np.power(mixed_model_pdf(points) - cook_kde,2)\n",
    "mse = np.average(error_array)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
